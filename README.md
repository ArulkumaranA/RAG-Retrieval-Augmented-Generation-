## Retrieval-Augmented Generation (RAG) Question Answering System
## Project Overview

This project implements a Retrieval-Augmented Generation (RAG) system using Large Language Models (LLMs) and vector databases.

The system retrieves relevant documents from a knowledge base and generates accurate, context-aware responses.

## Objective

-Load custom documents

-Convert text into embeddings

-Store embeddings in ChromaDB

-Retrieve relevant context

-Generate intelligent answers using LLM

## Technologies Used

-Python

-LangChain

-ChromaDB

-Google Gemini / OpenAI

-HuggingFace Embeddings

-Streamlit (optional)

 
 ## Workflow

1️ Load Documents
2️ Split into Chunks
3️ Generate Embeddings
4️ Store in Vector Database
5️ Create Retriever
6️ Generate Response using LLM

## Key Features

-Custom document-based Q&A

-Vector similarity search

-Context-aware response generation

-Scalable architecture

## Author

Arul Kumaran
Computer Science Engineering
Aspiring Data Scientist
