{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fa626f-07c0-4349-92e3-c987b93f27c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARUL KUMARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#Imports (FIXED)\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain_google_genai import (\n",
    "    GoogleGenerativeAIEmbeddings,\n",
    "    ChatGoogleGenerativeAI\n",
    ")\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87256fe2-8c86-4e2c-979c-04fc8cdd1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Google API Key\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"YOUR API KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaecb3cd-5a66-4cd9-b100-52f065e75679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ARUL KUMARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARUL KUMARAN\\AppData\\Local\\Temp\\ipykernel_29152\\2598141822.py:11: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "# LLM (FIXED ‚Äì init_chat_model REMOVED)\n",
    "from transformers import pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-small\",\n",
    "    max_new_tokens=200\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e8eb3b-b8af-489c-a5b4-a45a6bc8c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Web Documents\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    \"PYTHON PROGRAMMING NOTES.pdf\"\n",
    ")\n",
    "\n",
    "raw_docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd145a74-7381-4d2b-a6f0-8076b02ff9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Splitting\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "\n",
    "docs = splitter.split_documents(raw_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c14005a-dd0e-41a6-a5b3-37e35de5c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake embeddings loaded ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "\n",
    "\n",
    "embeddings = FakeEmbeddings(size=384)\n",
    "print(\"Fake embeddings loaded ‚úÖ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e334d762-2a8e-4e12-a0c0-ec8ec32226c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector Store + Retriever\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"selfrag-demo\"\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c8aa3e-3f89-4008-b47a-daf9df50af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Self-RAG Function (FIXED)\n",
    "\n",
    "def self_rag(question: str):\n",
    "\n",
    "    # Step 0: Retrieve context\n",
    "    context_docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in context_docs)\n",
    "\n",
    "    # Step 1: Initial Answer\n",
    "    prompt = f\"\"\"\n",
    "Answer the question using ONLY the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "    answer = llm.invoke(prompt)\n",
    "    print(\"Initial Answer:\\n\", answer)\n",
    "\n",
    "    # Step 2: Critique\n",
    "    critique_prompt = f\"\"\"\n",
    "You are a fact-checker.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Is the answer fully supported by the context?\n",
    "Say yes or no and explain.\n",
    "\"\"\"\n",
    "    critique = llm.invoke(critique_prompt)\n",
    "    print(\"\\nCritique:\\n\", critique)\n",
    "\n",
    "    # Step 3: Revise if needed\n",
    "    if \"no\" in critique.lower():\n",
    "        revise_prompt = f\"\"\"\n",
    "Improve the answer so it strictly matches the context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Original Answer:\n",
    "{answer}\n",
    "\n",
    "Revised Answer:\n",
    "\"\"\"\n",
    "        revised = llm.invoke(revise_prompt)\n",
    "        return revised\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd82d935-7a9f-4b0c-b51f-77b9ffc9512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  what is python?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      " python\n",
      "\n",
      "Critique:\n",
      " no\n",
      "\n",
      "üîç Final Answer:\n",
      " python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  what is function?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      " Output: Function definitions do not alter the flow of execution of the program, but remember that statements inside the function are not executed until the function is called.\n",
      "\n",
      "Critique:\n",
      " Output: yes\n",
      "\n",
      "üîç Final Answer:\n",
      " Output: Function definitions do not alter the flow of execution of the program, but remember that statements inside the function are not executed until the function is called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  what is list?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      "  Available Task List \n",
      "\n",
      "Critique:\n",
      " yes\n",
      "\n",
      "üîç Final Answer:\n",
      "  Available Task List \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  what is built in function?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      " a Python script\n",
      "\n",
      "Critique:\n",
      " Output: yes\n",
      "\n",
      "üîç Final Answer:\n",
      " a Python script\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  what is tuple?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      " Output: Tuple comprehension\n",
      "\n",
      "Critique:\n",
      " Output: no\n",
      "\n",
      "üîç Final Answer:\n",
      " Output: f(x): y0 = x + 1 y1 = x * 3 y2 = y0 ** y3 return (y0, y1, y2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  who is the author?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      " t\n",
      "\n",
      "Critique:\n",
      " No\n",
      "\n",
      "üîç Final Answer:\n",
      " t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  what is keywords?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      " tuple\n",
      "\n",
      "Critique:\n",
      " yes\n",
      "\n",
      "üîç Final Answer:\n",
      " tuple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  what is keyword arguments?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Answer:\n",
      " a keyword argument\n",
      "\n",
      "Critique:\n",
      " no\n",
      "\n",
      "üîç Final Answer:\n",
      " a keyword argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask your question (type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"\\nAsk your question (type 'exit' to quit): \")\n",
    "\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    response = self_rag(query)   # ‚úÖ Direct call\n",
    "    print(\"\\nüîç Final Answer:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be296213-3468-4b7b-b817-e2e896db6545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
